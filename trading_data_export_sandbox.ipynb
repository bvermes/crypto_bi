{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/exports'\n",
    "\n",
    "timeframe_array = ['1m','15m','1h','4h', '1d', '1w']\n",
    "timeframe_mapping = {'1m': '1min', '15m': '15min', '1h': '1h', '4h': '4h', '1d': '1D', '1w': '7D'}\n",
    "\n",
    "timeframe_array = [\n",
    "                '1m','15m','1h','4h', '1d', '1w',\n",
    "                #'1M'\n",
    "                ]\n",
    "symbol_array = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT','ICPUSDT', 'AVAXUSDT']\n",
    "\n",
    "interval_to_ms = {\n",
    "    \"1m\": 60_000,\n",
    "    \"3m\": 3 * 60_000,\n",
    "    \"5m\": 5 * 60_000,\n",
    "    \"15m\": 15 * 60_000,\n",
    "    \"30m\": 30 * 60_000,\n",
    "    \"1h\": 60 * 60_000,\n",
    "    \"2h\": 2 * 60 * 60_000,\n",
    "    \"4h\": 4 * 60 * 60_000,\n",
    "    \"6h\": 6 * 60 * 60_000,\n",
    "    \"8h\": 8 * 60 * 60_000,\n",
    "    \"12h\": 12 * 60 * 60_000,\n",
    "    \"1d\": 24 * 60 * 60_000,\n",
    "    \"3d\": 3 * 24 * 60 * 60_000,\n",
    "    \"1w\": 7 * 24 * 60 * 60_000,\n",
    "    \"1M\": 30 * 24 * 60 * 60_000  # approximate month (30 days)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import data.datasource.binance_api as ba \n",
    "\n",
    "import business.utils.trading_signals as ts\n",
    "import business.utils.trading_indicators as ti\n",
    "import presentation.plotter as pl\n",
    "\n",
    "\n",
    "base_start_time_1m = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "base_start_time_other = int(pd.Timestamp(\"2015-01-01\").timestamp() * 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_data_path(symbol, interval):\n",
    "    \"\"\"Return the exact file path if the CSV exists (case-sensitive for intervals).\"\"\"\n",
    "    filename = f\"data/exports/{symbol}_{interval}_data.csv\"\n",
    "    return filename if os.path.exists(filename) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_timestamp_from_csv(filepath):\n",
    "    \"\"\"Retrieve the last timestamp from an existing CSV file.\"\"\"\n",
    "    df = pd.read_csv(filepath, usecols=[\"timestamp\"])\n",
    "    if df.empty:\n",
    "        return None\n",
    "    last_timestamp = df[\"timestamp\"].iloc[-1]\n",
    "    return int(pd.Timestamp(last_timestamp).timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_historical_data(symbol, interval, start_time):\n",
    "    if interval not in interval_to_ms:\n",
    "        raise ValueError(f\"Interval {interval} not supported.\")\n",
    "\n",
    "    delta = interval_to_ms[interval]\n",
    "\n",
    "    all_data = []\n",
    "    start_overall = time.time()\n",
    "    iteration_count = 0\n",
    "\n",
    "    while True:\n",
    "        iteration_count += 1\n",
    "        klines = ba.get_binance_klines(symbol, interval, start_time, limit=1000)\n",
    "        if not klines:\n",
    "            print(\"No more data returned from Binance.\")\n",
    "            break\n",
    "\n",
    "        all_data += klines\n",
    "        # Advance start_time by the appropriate millisecond delta for the interval.\n",
    "        start_time = klines[-1][0] + delta\n",
    "\n",
    "        elapsed = time.time() - start_overall\n",
    "        latest_ts = klines[-1][0]\n",
    "        latest_dt = pd.to_datetime(latest_ts, unit='ms')\n",
    "        print(f\"Iteration {iteration_count}: Latest timestamp: {latest_ts} ({latest_dt}), \"\n",
    "              f\"Total records: {len(all_data)}, Elapsed time: {elapsed:.2f} sec\")\n",
    "\n",
    "        # If fewer than 'limit' records are returned, assume we've reached the end.\n",
    "        if len(klines) < 1000:\n",
    "            print(f\"Iteration {iteration_count}: Last batch retrieved with {len(klines)} records. Ending extraction.\")\n",
    "            break\n",
    "\n",
    "        # Respect Binance rate limits.\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Convert collected data into a DataFrame.\n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "        \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "        \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "    ])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit='ms')\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "    print(\"Data extraction complete. Sample data:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Export to CSV.\n",
    "    df.to_csv(f'data/exports/{symbol}_{interval}_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_data(symbol, interval, start_time, csv_path):\n",
    "    \"\"\"Append new data to an existing CSV file and save.\"\"\"\n",
    "    # Fetch new data from Binance\n",
    "    new_data = []\n",
    "    iteration_count = 0\n",
    "    start_overall = time.time()\n",
    "\n",
    "    while True:\n",
    "        iteration_count += 1\n",
    "        klines = ba.get_binance_klines(symbol, interval, start_time, limit=1000)\n",
    "        if not klines:\n",
    "            print(f\"{symbol} {interval}: No more data from Binance.\")\n",
    "            break\n",
    "\n",
    "        new_data += klines\n",
    "        start_time = klines[-1][0] + interval_to_ms[interval]\n",
    "\n",
    "        elapsed = time.time() - start_overall\n",
    "        latest_ts = klines[-1][0]\n",
    "        latest_dt = pd.to_datetime(latest_ts, unit='ms')\n",
    "        print(f\"{symbol} {interval} | Iteration {iteration_count}: Latest timestamp: {latest_dt}, \"\n",
    "              f\"Total new records: {len(new_data)}, Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "        if len(klines) < 1000:\n",
    "            print(f\"{symbol} {interval}: Last batch retrieved with {len(klines)} records. Reached end.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(0.5)  # Respect Binance rate limits\n",
    "\n",
    "    if not new_data:\n",
    "        print(f\"{symbol} {interval}: No new data to append.\")\n",
    "        return\n",
    "\n",
    "    # Convert collected data into a DataFrame\n",
    "    df_new = pd.DataFrame(new_data, columns=[\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "        \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "        \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "    ])\n",
    "    df_new[\"timestamp\"] = pd.to_datetime(df_new[\"timestamp\"], unit='ms')\n",
    "\n",
    "    # Load existing data\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_existing[\"timestamp\"] = pd.to_datetime(df_existing[\"timestamp\"])\n",
    "\n",
    "    # Combine and remove duplicates\n",
    "    df_combined = pd.concat([df_existing, df_new]).drop_duplicates(subset=[\"timestamp\"]).sort_values(by=\"timestamp\")\n",
    "\n",
    "    # Save updated CSV\n",
    "    df_combined.to_csv(csv_path, index=False)\n",
    "    print(f\"{symbol} {interval}: Data appended and saved. Total records: {len(df_combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_or_update(symbol, interval):\n",
    "    \"\"\"Check if export exists, update if yes, otherwise download from scratch.\"\"\"\n",
    "    csv_path = get_existing_data_path(symbol, interval)\n",
    "\n",
    "    if csv_path:\n",
    "        print(f\"âœ… {symbol} {interval}: Existing CSV found. Checking for updates...\")\n",
    "        last_timestamp = get_last_timestamp_from_csv(csv_path)\n",
    "        if last_timestamp:\n",
    "            print(f\"ðŸ“… Last recorded timestamp: {pd.to_datetime(last_timestamp, unit='ms')}\")\n",
    "            append_new_data(symbol, interval, last_timestamp, csv_path)\n",
    "        else:\n",
    "            start_time = base_start_time_1m if interval == \"1m\" else base_start_time_other\n",
    "            print(f\"âš ï¸ {symbol} {interval}: CSV is empty, starting from {pd.to_datetime(start_time, unit='ms')}...\")\n",
    "            export_historical_data(symbol, interval, start_time)\n",
    "    else:\n",
    "        start_time = base_start_time_1m if interval == \"1m\" else base_start_time_other\n",
    "        print(f\"ðŸš€ {symbol} {interval}: No existing data. Starting from {pd.to_datetime(start_time, unit='ms')}...\")\n",
    "        export_historical_data(symbol, interval, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_timeframes():\n",
    "    data = {}\n",
    "    \n",
    "    # Load datasets into a dictionary\n",
    "    for symbol in [\n",
    "                # 'BTCUSDT','ETHUSDT',\n",
    "                #'SOLUSDT',\n",
    "                #'ICPUSDT',\n",
    "                'AVAXUSDT'\n",
    "            ]:\n",
    "        for timeframe in timeframe_array:\n",
    "            file_path = os.path.join(data_folder, f'{symbol}_{timeframe}_data.csv')\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "                data[(symbol, timeframe)] = df.set_index('timestamp')\n",
    "    \n",
    "    for (symbol, timeframe), df in data.items():\n",
    "        higher_timeframes = [tf for tf in timeframe_array \n",
    "                             if pd.Timedelta(timeframe_mapping[tf]) > pd.Timedelta(timeframe_mapping[timeframe])]\n",
    "        \n",
    "        for ht in higher_timeframes:\n",
    "            if (symbol, ht) in data:\n",
    "                ht_df = data[(symbol, ht)].reindex(df.index, method='ffill')\n",
    "                df[f'{ht}_open'] = ht_df['open']\n",
    "                df[f'{ht}_high'] = ht_df['high']\n",
    "                df[f'{ht}_low'] = ht_df['low']\n",
    "                # Use the current close from the lower timeframe (since we don't know the higher timeframe's final close)\n",
    "                df[f'{ht}_close'] = df['close']\n",
    "        \n",
    "        output_path = os.path.join(data_folder, f'{symbol}_{timeframe}_data.csv')\n",
    "        df.reset_index().to_csv(output_path, index=False)\n",
    "        print(f'Saved merged file: {output_path}')\n",
    "def check_missing_intervals():\n",
    "    for timeframe, freq in timeframe_mapping.items():\n",
    "        for symbol in symbol_array:\n",
    "            file_path = os.path.join(data_folder, f'{symbol}_{timeframe}_data.csv')\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "                df = df.set_index('timestamp')\n",
    "                \n",
    "                # Check for duplicates\n",
    "                duplicates = df.index.duplicated().sum()\n",
    "                if duplicates > 0:\n",
    "                    print(f'{symbol}_{timeframe}: {duplicates} duplicate timestamps found.')\n",
    "                \n",
    "                # Check for missing intervals\n",
    "                all_times = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)\n",
    "                missing_times = all_times.difference(df.index)\n",
    "                if not missing_times.empty:\n",
    "                    print(f'{symbol}_{timeframe}: {len(missing_times)} missing timestamps.')\n",
    "                else:\n",
    "                    print(f'{symbol}_{timeframe}: No missing timestamps.')\n",
    "def find_missing_timestamps(df_name):\n",
    "    # Extract symbol and timeframe from dataframe name (e.g., 'BTCUSDT_1m')\n",
    "    symbol_timeframe = df_name.replace('_data', '').strip()  # Clean suffix if any\n",
    "    symbol, timeframe = symbol_timeframe.split('_')\n",
    "    \n",
    "    \n",
    "    file_path = f'data/exports/{df_name}.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(file_path, parse_dates=['timestamp']).set_index('timestamp')\n",
    "\n",
    "    if timeframe not in timeframe_mapping:\n",
    "        print(f\"Timeframe {timeframe} not recognized.\")\n",
    "        return None\n",
    "\n",
    "    # Create a full range of timestamps for the timeframe\n",
    "    freq = timeframe_mapping[timeframe]\n",
    "    full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)\n",
    "\n",
    "    # Find missing timestamps\n",
    "    missing_timestamps = full_range.difference(df.index)\n",
    "\n",
    "    # Create a dataframe for the missing timestamps\n",
    "    missing_df = pd.DataFrame({'timestamp': missing_timestamps})\n",
    "    \n",
    "    if missing_df.empty:\n",
    "        print(f\"No missing timestamps for {df_name}.\")\n",
    "    else:\n",
    "        print(f\"Found {len(missing_df)} missing timestamps for {df_name}.\")\n",
    "\n",
    "    return missing_df\n",
    "\n",
    "def insert_indicator_values(df):\n",
    "    df['RSI'], df['RSI_MA'] = ti.calculate_rsi_with_ma(df['close'], rsi_period=14, ma_type=\"SMA\", ma_length=14)\n",
    "    df['MACD'], df['Signal'], df['MACD_Hist'] = ti.calculate_macd(df['close'], fast_period=12, slow_period=26, signal_period=9)\n",
    "    df['BB_Mid'], df['BB_Upper'], df['BB_Lower'] = ti.calculate_bollinger_bands(df['close'], window=20, num_std=2)\n",
    "    df['Stoch_K'], df['Stoch_D'] = ti.calculate_stochastic(df, k_period=14, d_period=3)\n",
    "    df = ti.calculate_fibonacci_from_swings(df = df, suffix='_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbol_array:\n",
    "        for interval in timeframe_array:\n",
    "            print(f\"ðŸ“Š Processing {symbol} {interval}\")\n",
    "            export_or_update(symbol, interval)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert higher timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_timeframes()\n",
    "check_missing_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3357 missing timestamps for BTCUSDT_1m_data.\n"
     ]
    }
   ],
   "source": [
    "missing_df = find_missing_timestamps('BTCUSDT_1m_data')\n",
    "if missing_df is not None and not missing_df.empty:\n",
    "    missing_df.to_csv('BTCUSDT_1m_missing_timestamps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/exports/BTCUSDT_1m_data.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing = pd.read_csv('data/exports/BTCUSDT_1d_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <th>taker_buy_quote_asset_volume</th>\n",
       "      <th>ignore</th>\n",
       "      <th>1w_open</th>\n",
       "      <th>1w_high</th>\n",
       "      <th>1w_low</th>\n",
       "      <th>1w_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>1503014399999</td>\n",
       "      <td>3.454770e+06</td>\n",
       "      <td>3427</td>\n",
       "      <td>616.248541</td>\n",
       "      <td>2.678216e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>4285.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>1503100799999</td>\n",
       "      <td>5.086958e+06</td>\n",
       "      <td>5233</td>\n",
       "      <td>972.868710</td>\n",
       "      <td>4.129123e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>4108.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "      <td>1503187199999</td>\n",
       "      <td>1.549484e+06</td>\n",
       "      <td>2153</td>\n",
       "      <td>274.336042</td>\n",
       "      <td>1.118002e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>4139.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "      <td>1503273599999</td>\n",
       "      <td>1.930364e+06</td>\n",
       "      <td>2321</td>\n",
       "      <td>376.795947</td>\n",
       "      <td>1.557401e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>4086.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "      <td>1503359999999</td>\n",
       "      <td>2.797232e+06</td>\n",
       "      <td>3972</td>\n",
       "      <td>557.356107</td>\n",
       "      <td>2.255663e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4453.91</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>4016.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp     open     high      low    close       volume     close_time  \\\n",
       "0  2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377  1503014399999   \n",
       "1  2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264  1503100799999   \n",
       "2  2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763  1503187199999   \n",
       "3  2017-08-20  4120.98  4211.08  4032.62  4086.29   467.083022  1503273599999   \n",
       "4  2017-08-21  4069.13  4119.62  3911.79  4016.00   691.743060  1503359999999   \n",
       "\n",
       "   quote_asset_volume  number_of_trades  taker_buy_base_asset_volume  \\\n",
       "0        3.454770e+06              3427                   616.248541   \n",
       "1        5.086958e+06              5233                   972.868710   \n",
       "2        1.549484e+06              2153                   274.336042   \n",
       "3        1.930364e+06              2321                   376.795947   \n",
       "4        2.797232e+06              3972                   557.356107   \n",
       "\n",
       "   taker_buy_quote_asset_volume  ignore  1w_open  1w_high  1w_low  1w_close  \n",
       "0                  2.678216e+06       0  4261.48  4485.39  3850.0   4285.08  \n",
       "1                  4.129123e+06       0  4261.48  4485.39  3850.0   4108.37  \n",
       "2                  1.118002e+06       0  4261.48  4485.39  3850.0   4139.98  \n",
       "3                  1.557401e+06       0  4261.48  4485.39  3850.0   4086.29  \n",
       "4                  2.255663e+06       0  4069.13  4453.91  3400.0   4016.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_existing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Desktop\\git\\crypto_bi\\business\\utils\\trading_indicators.py:406: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Downtrend' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[recent_low_idx:current_idx, list(fib_levels.keys())] = list(\n"
     ]
    }
   ],
   "source": [
    "df_with_fib = ti.calculate_fibonacci_from_swings(df = df_existing, suffix='_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>fib_100_val</th>\n",
       "      <th>fib_78_6_val</th>\n",
       "      <th>fib_61_8_val</th>\n",
       "      <th>fib_50_val</th>\n",
       "      <th>fib_38_2_val</th>\n",
       "      <th>fib_23_6_val</th>\n",
       "      <th>fib_0_val</th>\n",
       "      <th>swing_high_val_val</th>\n",
       "      <th>swing_low_val_val</th>\n",
       "      <th>trend_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>97430.82</td>\n",
       "      <td>98478.42</td>\n",
       "      <td>94876.88</td>\n",
       "      <td>95778.20</td>\n",
       "      <td>18647.76379</td>\n",
       "      <td>1739318399999</td>\n",
       "      <td>1.806535e+09</td>\n",
       "      <td>3716586</td>\n",
       "      <td>8594.50066</td>\n",
       "      <td>...</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>98750.612</td>\n",
       "      <td>90242.756</td>\n",
       "      <td>84267.0</td>\n",
       "      <td>78291.244</td>\n",
       "      <td>70897.512</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>Uptrend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>95778.21</td>\n",
       "      <td>98119.99</td>\n",
       "      <td>94088.23</td>\n",
       "      <td>97869.99</td>\n",
       "      <td>29151.16625</td>\n",
       "      <td>1739404799999</td>\n",
       "      <td>2.800142e+09</td>\n",
       "      <td>4992737</td>\n",
       "      <td>13820.70553</td>\n",
       "      <td>...</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>98750.612</td>\n",
       "      <td>90242.756</td>\n",
       "      <td>84267.0</td>\n",
       "      <td>78291.244</td>\n",
       "      <td>70897.512</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>Uptrend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>97870.00</td>\n",
       "      <td>98083.91</td>\n",
       "      <td>95217.36</td>\n",
       "      <td>96608.14</td>\n",
       "      <td>19921.77616</td>\n",
       "      <td>1739491199999</td>\n",
       "      <td>1.916988e+09</td>\n",
       "      <td>3909456</td>\n",
       "      <td>8852.16215</td>\n",
       "      <td>...</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>98750.612</td>\n",
       "      <td>90242.756</td>\n",
       "      <td>84267.0</td>\n",
       "      <td>78291.244</td>\n",
       "      <td>70897.512</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>Uptrend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>96608.13</td>\n",
       "      <td>98826.00</td>\n",
       "      <td>96252.82</td>\n",
       "      <td>97500.48</td>\n",
       "      <td>18173.02646</td>\n",
       "      <td>1739577599999</td>\n",
       "      <td>1.768073e+09</td>\n",
       "      <td>3499564</td>\n",
       "      <td>9061.31682</td>\n",
       "      <td>...</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>98750.612</td>\n",
       "      <td>90242.756</td>\n",
       "      <td>84267.0</td>\n",
       "      <td>78291.244</td>\n",
       "      <td>70897.512</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>Uptrend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>2025-02-15</td>\n",
       "      <td>97500.47</td>\n",
       "      <td>97972.26</td>\n",
       "      <td>97223.58</td>\n",
       "      <td>97624.00</td>\n",
       "      <td>3511.58360</td>\n",
       "      <td>1739663999999</td>\n",
       "      <td>3.426550e+08</td>\n",
       "      <td>789655</td>\n",
       "      <td>1659.38802</td>\n",
       "      <td>...</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>98750.612</td>\n",
       "      <td>90242.756</td>\n",
       "      <td>84267.0</td>\n",
       "      <td>78291.244</td>\n",
       "      <td>70897.512</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>109588.0</td>\n",
       "      <td>58946.0</td>\n",
       "      <td>Uptrend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "2735  2025-02-11  97430.82  98478.42  94876.88  95778.20  18647.76379   \n",
       "2736  2025-02-12  95778.21  98119.99  94088.23  97869.99  29151.16625   \n",
       "2737  2025-02-13  97870.00  98083.91  95217.36  96608.14  19921.77616   \n",
       "2738  2025-02-14  96608.13  98826.00  96252.82  97500.48  18173.02646   \n",
       "2739  2025-02-15  97500.47  97972.26  97223.58  97624.00   3511.58360   \n",
       "\n",
       "         close_time  quote_asset_volume  number_of_trades  \\\n",
       "2735  1739318399999        1.806535e+09           3716586   \n",
       "2736  1739404799999        2.800142e+09           4992737   \n",
       "2737  1739491199999        1.916988e+09           3909456   \n",
       "2738  1739577599999        1.768073e+09           3499564   \n",
       "2739  1739663999999        3.426550e+08            789655   \n",
       "\n",
       "      taker_buy_base_asset_volume  ...  fib_100_val  fib_78_6_val  \\\n",
       "2735                   8594.50066  ...     109588.0     98750.612   \n",
       "2736                  13820.70553  ...     109588.0     98750.612   \n",
       "2737                   8852.16215  ...     109588.0     98750.612   \n",
       "2738                   9061.31682  ...     109588.0     98750.612   \n",
       "2739                   1659.38802  ...     109588.0     98750.612   \n",
       "\n",
       "      fib_61_8_val  fib_50_val  fib_38_2_val  fib_23_6_val  fib_0_val  \\\n",
       "2735     90242.756     84267.0     78291.244     70897.512    58946.0   \n",
       "2736     90242.756     84267.0     78291.244     70897.512    58946.0   \n",
       "2737     90242.756     84267.0     78291.244     70897.512    58946.0   \n",
       "2738     90242.756     84267.0     78291.244     70897.512    58946.0   \n",
       "2739     90242.756     84267.0     78291.244     70897.512    58946.0   \n",
       "\n",
       "      swing_high_val_val  swing_low_val_val  trend_val  \n",
       "2735            109588.0            58946.0    Uptrend  \n",
       "2736            109588.0            58946.0    Uptrend  \n",
       "2737            109588.0            58946.0    Uptrend  \n",
       "2738            109588.0            58946.0    Uptrend  \n",
       "2739            109588.0            58946.0    Uptrend  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_fib.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pl\u001b[38;5;241m.\u001b[39mplot_fibonacci_chart(df_with_fib, selected_index\u001b[38;5;241m=\u001b[39mdf_with_fib\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFibonacci Retracement - 1D\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_val\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\Desktop\\git\\crypto_bi\\presentation\\plotter.py:78\u001b[0m, in \u001b[0;36mplot_fibonacci_chart\u001b[1;34m(df, selected_index, title, suffix)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_index \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m level_name, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fib_columns, colors):\n\u001b[1;32m---> 78\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m level_name \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(\n\u001b[0;32m     79\u001b[0m             df\u001b[38;5;241m.\u001b[39mloc[selected_index, level_name]\n\u001b[0;32m     80\u001b[0m         ):\n\u001b[0;32m     81\u001b[0m             level_value \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[selected_index, level_name]\n\u001b[0;32m     82\u001b[0m             fig\u001b[38;5;241m.\u001b[39madd_trace(\n\u001b[0;32m     83\u001b[0m                 go\u001b[38;5;241m.\u001b[39mScatter(\n\u001b[0;32m     84\u001b[0m                     x\u001b[38;5;241m=\u001b[39m[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 )\n\u001b[0;32m     90\u001b[0m             )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pl.plot_fibonacci_chart(df_with_fib, selected_index=df_with_fib.index[-1], title=\"Fibonacci Retracement - 1D\", suffix=\"_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPORT HISTORY\n",
    "\n",
    "symbol = \"BTCUSDT\"\n",
    "interval = \"1m\"\n",
    "start_time = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "export_historical_data(symbol, interval, start_time)\n",
    "\n",
    "symbol = \"ETHUSDT\"\n",
    "interval = \"1m\"\n",
    "start_time = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "export_historical_data(symbol, interval, start_time)\n",
    "\n",
    "symbol = \"SOLUSDT\"\n",
    "interval = \"1m\"\n",
    "start_time = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "export_historical_data(symbol, interval, start_time)\n",
    "\n",
    "symbol = \"ICPUSDT\"\n",
    "interval = \"1m\"\n",
    "start_time = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "export_historical_data(symbol, interval, start_time)\n",
    "\n",
    "symbol = \"AVAXUSDT\"\n",
    "interval = \"1m\"\n",
    "start_time = int(pd.Timestamp(\"2019-01-01\").timestamp() * 1000)\n",
    "export_historical_data(symbol, interval, start_time)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
